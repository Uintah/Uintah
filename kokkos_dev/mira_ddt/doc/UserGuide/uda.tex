\chapter{Uda Management } \label{Chapter:UDA}
Uintah offers a number of tools for managing Uintah Data Archives (``UDAs''). These tools are especially useful for large simulations with large output.  These tools are used for quickly moving data, reducing the size and number of variables within your UDA and combining multiple UDAs. 

\section{ReduceUda}
The typical mode of operation with production runs is to save all the variables you think you'll ever
want to analyze, run the series of simulations, look at the data and then sit on the udas until you're
 forced to move them or delete them.  To help manage the size of the udas there's a new component
(reduce\_uda) that allows users to prune out variables from an existing udas.   This component takes your existing uda,
reads the input.xml file, and outputs the modified set of variables to a new uda, leaving the original uda untouched.
Below are instructions:
\begin{enumerate}
\item In the input.xml file set the simulation component type to ``reduce\_uda'', 

$<$SimulationComponent type=``reduce\_uda''/$>$
\item To avoid confusion with the original directory  change the uda name
   $<$filebase$>$UDA-diet.uda$<$/filebase$>$

\item Modify the DataArchiver section to restrict the data that will be saved.  Below are the available options:
   \begin{itemize}
     \item Resave the variables as floats using $<$outputDoubleAsFloat/$>$
     \item Remove variables from an uda by commenting them out
     \item For each variable limit the materials that are saved by using the 
    
     ``material=X'' option in the save label spec.
     \item For each variable limit the levels that it is saved on by using ``levels=X'' option in the save labels spec.
  \end{itemize}
For example to convert all of the doubles variables to floats and limit the variable vel\_CC to be
saved for material 1 make the following changes:

$<$outputDoubleAsFloat/$>$

$<$save label=``vel\_CC'' material=``1''/$>$


\item run the following command.

    mpirun -np X sus -reduce\_uda $<$name of uda directory$>$
    
    This will produce a new uda directory with the pruned variables. All time steps and checkpoints will be copied along with the index.xml, input file, input.xml and .dat files.

\end{enumerate}

When using this tool please be aware of the following:
\begin{itemize}
   \item If you're using this on a machine with a reduced set of system calls (tukey) configure with
          (- -with-boost)  This will enable the boost copy functions.
    \item Reduce\_uda will not work on ALCF machines (expect tukey)
    \item You must manually copy all On-the-Fly files/directories from the original uda
      to the new uda, reduce\_uda ignores them.
    \item The $<$outputInterval$>$, $<$outputTimestepInterval$>$ tags are ignored and every
      timestep in the original uda is processed.  If you want to prune timesteps
      you must manually delete timesteps directories and modify the index.xml file.
    \item Use a different uda name for the modifed uda to prevent confusion with the original uda.
    \item In the timestep.xml files the following non-essential entries will be changed:
    
           numProcs:      Number of procs used during the reduceUda run.
           
           oldDelt:       Difference in timesteps, i.e., time(TS) - time (TS-1), in physical time.
           
           proc:          The processor to patch assignment.
    \item The number of files inside of a timestep directory will now equal the number of processors used to reduce the uda.
        You should use the same number of processors to reduce the uda as you will use to visualize it.
         For large runs this should speed up data transfers and post processing utilities.

    \item Checkpoint directories are copied with system calls from the original -$>$ modified uda.
      Only 1 processor is used during the copy so this will be slow for large checkpoints directories.
      Consider moving this manually.
    \item ALWAYS, ALWAYS, ALWAYS verify that the new (modified) uda is consistent
      with your specfications before deleting the original uda.
 \end{itemize}

\section{pscp2}
pscp2 is a tool to quickly transfer data in parallel between two machines. In order for this to work there must be an password-less connection between the two machines. pscp2 is located in /src/scripts/udaTransferScripts/

$\ $

The usage is 

$\ $

 ./pscp2 $<$$\#$ processors$>$ $<$transfer entire uda (y/n)$>$ $<$remove remote directory (y/n)$>$ $<$local directory$>$ $<$login@remote macihng$>$:$<$remote path$>$
 
$\ $
 
 The following example shows the usage of pscp2 for transferring 1.uda.000 from the local machine to the home directory on ember using 8 processors. It will remove any files in the home directory on ember with the same title of 1.uda.000 but the original copy on the local machine will not be removed.
 
$\ $
 
 ./pscp2 8 y n 1.uda.000 username@ember.chpc.utah.edu:/home/

\section{Make Master Uda}
Make master UDA is a tool used to combine multiple UDAs. This will be useful when a simulation must be restarted multiple times and post processing is required. Instead of having to do post processing on each individual UDA, make master UDA will combine all of the UDAs to allow for continuous analysis of the simulation start to finish. In order for this to work the UDAs must be in sequential order, it does not mater what the UDA number is as long as they go in order.  This tool is found in /src/scripts/makeMasterUda.csh. When using this script it must be able to see /src/scripts/makeCombinedIndex.sh. This tool uses links to combine all of the UDAs, once the script is complete the original UDAs must stay were they are so the new master UDA can find the data. No changes will be made to the original UDAs.

$\ $

The usage is 
\begin{enumerate}
\item mkdir $<$masterUda$>$ This is where all of the UDAs will be linked together
\item cd $<$masterUda$>$
\item makeMasterUda.csh ../uda.000 ../uda.001 ../uda.00N


\end{enumerate}

